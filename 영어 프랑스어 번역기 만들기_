{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17715,"status":"ok","timestamp":1680446105416,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"mojeyU6f1kht","outputId":"5713d729-d3d2-4b51-ac4b-2aa593ddf0c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4211,"status":"ok","timestamp":1680446109626,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"POV2wMTlnn4j"},"outputs":[],"source":["import pandas as pd\n","import unicodedata\n","import re\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680446109626,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"stWWUJW7pbdi"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1680446110133,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Sh18HTVt1kj3"},"outputs":[],"source":["path = '/content/drive/MyDrive/딥러닝 스터디/eng_-french.csv'\n","data = pd.read_csv(path)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680446110134,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"OcKN7gtT1kl8","outputId":"2eaf5ece-e1fb-4dd7-91ae-19efb032cef3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  English words/sentences French words/sentences\n","0                     Hi.                 Salut!\n","1                    Run!                Cours !\n","2                    Run!               Courez !\n","3                    Who?                  Qui ?\n","4                    Wow!             Ça alors !"],"text/html":["\n","  <div id=\"df-ec89ddbd-b301-4c5f-a31a-e3ee4a985b04\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English words/sentences</th>\n","      <th>French words/sentences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hi.</td>\n","      <td>Salut!</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Run!</td>\n","      <td>Cours !</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Run!</td>\n","      <td>Courez !</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Who?</td>\n","      <td>Qui ?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Wow!</td>\n","      <td>Ça alors !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec89ddbd-b301-4c5f-a31a-e3ee4a985b04')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ec89ddbd-b301-4c5f-a31a-e3ee4a985b04 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ec89ddbd-b301-4c5f-a31a-e3ee4a985b04');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}],"source":["data.head(5)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680446110134,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"SmL2fMyw1kqC"},"outputs":[],"source":["#열 이름이이 너무 길어서 바꿔줬음\n","data.rename(columns={'French words/sentences':'Fr', 'English words/sentences': 'En'}, inplace= True)"]},{"cell_type":"markdown","metadata":{"id":"z9dFWnpjwwb3"},"source":["### 프랑스어 데이터 전처리리"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2176,"status":"ok","timestamp":1680446112302,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"DJ27jJKyrn5-"},"outputs":[],"source":["no_acent_fr = []\n","\n","for sentence in data['Fr']:\n","    string = ''\n","    #sentance를 유니코드 정규화를 통해 분해. 그러면 여러개의 문자가 되겠지?\n","    for c in unicodedata.normalize('NFD', sentence):\n","        # c는 문자임 이게 발음기호나 엑센트를 제거한 문자라면     \n","        if unicodedata.category(c) != 'Mn':\n","            #합쳐서 다시 문자열로 만들어줘 \n","            string = string + c\n","\n","    no_acent_fr.append(string)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680446112303,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"8WjVYRZutrCO","outputId":"340bf5b8-d285-4bc0-f50f-7ebb8824a417"},"outputs":[{"output_type":"stream","name":"stdout","text":["Arrete-toi !\n","Arrête-toi !\n"]}],"source":["#그러면 이렇게 변함!\n","print(no_acent_fr[10])\n","print(data['Fr'][10])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680446112303,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"0xcv_Lp9vZ-D","outputId":"b645cda8-373a-4129-d9d4-08153455fd08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Serre les dents.\n"]}],"source":["print(data['Fr'][10003]) #단어와 구두점 사이에 공백이 없음"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1651,"status":"ok","timestamp":1680446113952,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Aw7v54vTu05R"},"outputs":[],"source":["for i in range(len(no_acent_fr)):\n","    #특수문자 사이에 공백 만들어줌\n","    no_acent_fr[i] = re.sub(r\"([?.!,¿])\", r\" \\1\", no_acent_fr[i])\n","    \n","    #밑에 적혀있는거 빼고 공백으로 대체\n","    no_acent_fr[i] = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", no_acent_fr[i])\n","\n","    no_acent_fr[i] = re.sub(r\"\\s+\", \" \", no_acent_fr[i])"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680446113952,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"yCdoWocbsku6","outputId":"6e493e25-bed5-4d6f-e357-1ad7683b898d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Serre les dents.\n","Serre les dents .\n"]}],"source":["print(data['Fr'][10003])\n","print(no_acent_fr[10003])"]},{"cell_type":"markdown","metadata":{"id":"_EhEDG9Dw2hy"},"source":["### 영어 데이터 전처리"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1324,"status":"ok","timestamp":1680446115274,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"IS5IcJ00wtP0"},"outputs":[],"source":["no_acent_en = []\n","\n","for sentence in data['En']:\n","    string = ''\n","    #sentance를 유니코드 정규화를 통해 분해. 그러면 여러개의 문자가 되겠지?\n","    for c in unicodedata.normalize('NFD', sentence):\n","        # c는 문자임 이게 발음기호나 엑센트를 제거한 문자라면     \n","        if unicodedata.category(c) != 'Mn':\n","            #합쳐서 다시 문자열로 만들어줘 \n","            string = string + c\n","\n","    no_acent_en.append(string)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":2061,"status":"ok","timestamp":1680446117333,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"bYXcc-42w_gA"},"outputs":[],"source":["for i in range(len(no_acent_en)):\n","    #특수문자 사이에 공백 만들어줌\n","    no_acent_en[i] = re.sub(r\"([?.!,¿])\", r\" \\1\", no_acent_en[i])\n","    \n","    #밑에 적혀있는거 빼고 공백으로 대체\n","    no_acent_en[i] = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", no_acent_en[i])\n","\n","    no_acent_en[i] = re.sub(r\"\\s+\", \" \", no_acent_en[i])"]},{"cell_type":"markdown","metadata":{"id":"qhlhH0rlxXjW"},"source":["### 이제 sos 랑 eos 토근 추가할거임"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1680446117770,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"S4dhOi24xSpg"},"outputs":[],"source":["###프랑스어 #######\n","\n","encoder_fr = []\n","decoder_fr = []\n","\n","for i in range(len(no_acent_fr)):\n","    string_encoder = '<sos> ' + no_acent_fr[i]\n","    string_decoder = no_acent_fr[i] + ' <eos>'\n","    encoder_fr.append(string_encoder.split())\n","    decoder_fr.append(string_decoder.split())\n","\n","    # encoder_fr.append(string_encoder)\n","    # decoder_fr.append(string_decoder)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1680446118146,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"ytuGijqY_1fZ"},"outputs":[],"source":["sentence_en = []\n","\n","for i in no_acent_en:\n","    sentence_en.append(i.split())"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1680446118429,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"RP_qXxGoxShg","outputId":"471cc81e-93f6-41fa-9417-b7dae11b9a32"},"outputs":[{"output_type":"stream","name":"stdout","text":["[['<sos>', 'Salut', '!'], ['<sos>', 'Cours', '!'], ['<sos>', 'Courez', '!'], ['<sos>', 'Qui', '?'], ['<sos>', 'Ca', 'alors', '!']]\n","[['Salut', '!', '<eos>'], ['Cours', '!', '<eos>'], ['Courez', '!', '<eos>'], ['Qui', '?', '<eos>'], ['Ca', 'alors', '!', '<eos>']]\n","[['Hi', '.'], ['Run', '!'], ['Run', '!'], ['Who', '?'], ['Wow', '!']]\n"]}],"source":["print(encoder_fr[:5])\n","print(decoder_fr[:5])\n","print(sentence_en[:5])"]},{"cell_type":"markdown","metadata":{"id":"dDZNqeokGU5f"},"source":["### 토큰화 합니다"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":284,"status":"error","timestamp":1680447670987,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"hXnFWUp6AR6A","colab":{"base_uri":"https://localhost:8080/","height":148},"outputId":"4a39748c-9684-4a5a-b282-c29a00ddaf5c"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-0dec7240f0df>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    tokenizer_en('<sos>') = Tokenizer(filters=\"\", lower=True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to function call\n"]}],"source":["#filters = ' ' 하면 특수문자 필터링 안됨 lower=True 는 대소문자 구분안한다\n","tokenizer_en() = Tokenizer(filters=\"\", lower=True)\n","#각 단어에 대한 인덱스를 만들어줌 = 전체 텍스트에 대한 단어장임 이게\n","tokenizer_en.fit_on_texts(sentence_en) \n","#단어를 숫자로 변환해줌 \n","encoder_input = tokenizer_en.texts_to_sequences(sentence_en)"]},{"cell_type":"code","source":["tokenizer_en.texts_to_sequences('<sos> <eos>')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhREkhCOfLoF","executionInfo":{"status":"ok","timestamp":1680447848686,"user_tz":-540,"elapsed":365,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}},"outputId":"537c48d6-1942-4f7b-9ed4-e961bc9d3a8c"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[], [14], [770], [14], [], [], [], [3907], [770], [14], []]"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1680446121197,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"6VMT5WK7FfBX"},"outputs":[],"source":["encoder_input_len = 0\n","for i in encoder_input:\n","    encoder_input_len = max(len(i) , encoder_input_len)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1680446121650,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"y3xz4OuSFsNM"},"outputs":[],"source":["encoder_input_len\n","\n","#패딩 줘서 입력시퀀스 길이를 맞춰주는거임 일단 최대길이가 49니까 25만 줘보겠음\n","encoder_input = pad_sequences(encoder_input, maxlen = 25 )"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1680446121650,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"ZYWTQtIkGlLx"},"outputs":[],"source":["#사전의 길이 만든거임 \n","en_dic = len(tokenizer_en.word_index) + 1"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1680446121650,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Ck3rUmDaIHmg"},"outputs":[],"source":["#정답 데이터 만든거임 \n","en_to_index = tokenizer_en.word_index\n","index_to_en = tokenizer_en.index_word"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":3950,"status":"ok","timestamp":1680446125599,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Jk15nkCoCYLX"},"outputs":[],"source":["#####프랑스어_인풋, 아웃풋 토큰화 \n","\n","tokenizer_fr = Tokenizer(filters=\"\", lower=True)\n","tokenizer_fr.fit_on_texts(encoder_fr)\n","tokenizer_fr.fit_on_texts(decoder_fr)\n","\n","decoder_input = tokenizer_fr.texts_to_sequences(encoder_fr)\n","# decoder_input = pad_sequences(decoder_input, max_len = ,)\n","\n","decoder_output = tokenizer_fr.texts_to_sequences(decoder_fr)\n","# decoder_output = pad_sequences(decoder_output, max_len = ,)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680446125599,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"_UDvSWeKGyKA","outputId":"e9fd3420-bec9-40b8-c260-048701019b98"},"outputs":[{"output_type":"stream","name":"stdout","text":["62\n"]}],"source":["decoder_input_len = 0\n","for i in decoder_input:\n","    decoder_input_len = max(len(i) , decoder_input_len)\n","    \n","print(decoder_input_len)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1303,"status":"ok","timestamp":1680446126900,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"of84ts5EHGvU"},"outputs":[],"source":["decoder_input = pad_sequences(decoder_input, maxlen = 31)\n","decoder_output = pad_sequences(decoder_output, maxlen = 31)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680446126900,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"u35GWN8wHqzI"},"outputs":[],"source":["#사전 길이 만든거임 \n","fr_dic = len(tokenizer_fr.word_index) + 1"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680446126901,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"7OcOCtHBIPNR"},"outputs":[],"source":["#정답 데이터 만든거임 \n","fr_to_index = tokenizer_fr.word_index\n","index_to_fr = tokenizer_fr.index_word"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680446126901,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Y-3CH9fsHQsi","outputId":"04fa4d25-af79-4d43-a721-b8233202d787"},"outputs":[{"output_type":"stream","name":"stdout","text":["(175621, 25)\n","(175621, 31)\n","(175621, 31)\n"]}],"source":["print(encoder_input.shape)\n","print(decoder_input.shape)\n","print(decoder_output.shape)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680446126901,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"247X5Ij1HYsI","outputId":"cc5def58-857d-427e-aeab-e4420dcb1023"},"outputs":[{"output_type":"stream","name":"stdout","text":["13910 22850\n"]}],"source":["print(en_dic, fr_dic)"]},{"cell_type":"markdown","metadata":{"id":"4qel89HKH8wZ"},"source":["### 데이터 셋 만들기"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680446126901,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"1GPeQ3hqJ7tK"},"outputs":[],"source":["# encoder_input_train, encoder_input_test , decoder_input_train, decoder_input_test, decoder_output_train, decoder_output_test = train_test_split(encoder_input ,decoder_input,decoder_output,   test_size= 0.3,shuffle=True)\n","encoder_input_train = encoder_input[:30000]\n","decoder_input_train = decoder_input[:30000]\n","decoder_output_train = decoder_output[:30000] "]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680446126902,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"IRGarb3rV6Ct","outputId":"19ad782c-711b-4ef3-da11-2693ecced498"},"outputs":[{"output_type":"stream","name":"stdout","text":["(30000, 25)\n","(30000, 31)\n","(30000, 31)\n"]}],"source":["# print(encoder_input_train.shape, encoder_input_test.shape)\n","# print(decoder_input_train.shape,decoder_input_test.shape)\n","# print(decoder_output_train.shape,decoder_output_test.shape)\n","print(encoder_input_train.shape)\n","print(decoder_input_train.shape)\n","print(decoder_output_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"8-Anq2JYWdWJ"},"source":["### 모델 만들기"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3965,"status":"ok","timestamp":1680446130863,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"gf4g9aGTJ8En"},"outputs":[],"source":["##인코더 만들기#######\n","\n","embedding_dim = 64\n","hidden_dim = 32\n","\n","keras.backend.clear_session()\n","#none을 준 이유는 입력시퀀스 길이가 가변적이라서 \n","encoder_layer = keras.layers.Input(shape=(None,))\n","#단어를 고정길이 벡터로 변환해주는거임임 이미 숫자로 바꿔줘서 굳이 안해줘도 됨 \n","####embed_layer = keras.layers.Embedding(en_dic, embedding_dim)(encoder_layer)\n","#이건 왜하냐면 0으로 채워진 부분만 마스킹함. 입력시퀀스 길이가 변하니까 패딩된 값을 무시하게 해줌 \n","masking_layer = keras.layers.Masking(mask_value=0.0)(embed_layer)\n","#return_sequences=False 해주는 이유는 번역기에서는 그런거필요없음 return_state= True는 해야지 왜? 마지막상태태 리턴해줘야지 \n","lstm_layer = keras.layers.LSTM(hidden_dim, return_state= True, return_sequences=False)\n","#lstm 은 3개의 값을 리턴함 ㅇㅇㅇㅇㅇ\n","eocoder_output_layer, hidden_state, cell_state = lstm_layer(masking_layer)\n","#lstm의 마지막 상태를 저장해요 왜냐면 이게 디코더 처음값으로 들어가용 \n","encoder_last_states = [hidden_state, cell_state ]"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1680446131277,"user":{"displayName":"hyun kim","userId":"01411993080668172019"},"user_tz":-540},"id":"Cr0Z-Y3GacpN"},"outputs":[],"source":["##디코더 만들기####\n","\n","#none을 준 이유는 입력시퀀스 길이가 가변적이라서\n","decoder_layer = keras.layers.Input(shape=(None, ))\n","#단어를 고정길이 벡터로 변환해주는거임\n","embed_layer = keras.layers.Embedding(fr_dic, hidden_dim)(decoder_layer)\n","#이건 왜하냐면 0으로 채워진 부분만 마스킹함. 입력시퀀스 길이가 변하니까 패딩된 값을 무시하게 해줌\n","masking_layer = keras.layers.Masking(mask_value=0.0)(embed_layer)\n","#return_sequences=True 모든 시점에 대해서 단어 예측해줘야지지  return_state= True 마지막상태 리턴해줘야지 그래야 다음 디코더에 넣어주지\n","lstm_layer = keras.layers.LSTM(hidden_dim, return_state= True, return_sequences=True)\n","#디코더는 셀이랑 히든스테이트값이 필요가 없음 masking_layer와 encoder_last_states를 입력값으로 넣어줌 \n","decoder_outputs, _, _ = lstm_layer(masking_layer, initial_state=encoder_last_states)\n","#확률값으로 변환할게용용\n","\n","decoder_dense = keras.layers.Dense(fr_dic, activation='softmax')\n","dense_layer = decoder_dense(decoder_outputs)\n","\n","#모델 시작과 끝 지정\n","model = keras.models.Model(inputs=[encoder_layer, decoder_layer], outputs=dense_layer)\n","\n","#컴파일 sparse_categorical_crossentropy 이거쓰면 원핫인코딩으로 변환하지않아도됨\n","model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)"],"metadata":{"id":"9VTUowYEpjZp","executionInfo":{"status":"ok","timestamp":1680446131277,"user_tz":-540,"elapsed":3,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yndWNXcleGzT","executionInfo":{"status":"ok","timestamp":1680447283400,"user_tz":-540,"elapsed":1152125,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}},"outputId":"ee0f307b-312c-4871-ff07-8ccf44741f05"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","750/750 [==============================] - 61s 64ms/step - loss: 2.2592 - accuracy: 0.7980 - val_loss: 1.3453 - val_accuracy: 0.7757\n","Epoch 2/50\n","750/750 [==============================] - 40s 53ms/step - loss: 0.9919 - accuracy: 0.8389 - val_loss: 1.0753 - val_accuracy: 0.8409\n","Epoch 3/50\n","750/750 [==============================] - 35s 47ms/step - loss: 0.8543 - accuracy: 0.8655 - val_loss: 1.0050 - val_accuracy: 0.8474\n","Epoch 4/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.8021 - accuracy: 0.8718 - val_loss: 0.9677 - val_accuracy: 0.8498\n","Epoch 5/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.7691 - accuracy: 0.8736 - val_loss: 0.9436 - val_accuracy: 0.8523\n","Epoch 6/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.7432 - accuracy: 0.8765 - val_loss: 0.9227 - val_accuracy: 0.8540\n","Epoch 7/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.7123 - accuracy: 0.8818 - val_loss: 0.8907 - val_accuracy: 0.8609\n","Epoch 8/50\n","750/750 [==============================] - 39s 51ms/step - loss: 0.6817 - accuracy: 0.8861 - val_loss: 0.8675 - val_accuracy: 0.8644\n","Epoch 9/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.6560 - accuracy: 0.8895 - val_loss: 0.8496 - val_accuracy: 0.8662\n","Epoch 10/50\n","750/750 [==============================] - 38s 51ms/step - loss: 0.6341 - accuracy: 0.8917 - val_loss: 0.8335 - val_accuracy: 0.8684\n","Epoch 11/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.6133 - accuracy: 0.8939 - val_loss: 0.8174 - val_accuracy: 0.8696\n","Epoch 12/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.5895 - accuracy: 0.8967 - val_loss: 0.8012 - val_accuracy: 0.8725\n","Epoch 13/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.5687 - accuracy: 0.8994 - val_loss: 0.7891 - val_accuracy: 0.8745\n","Epoch 14/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.5500 - accuracy: 0.9014 - val_loss: 0.7763 - val_accuracy: 0.8768\n","Epoch 15/50\n","750/750 [==============================] - 38s 51ms/step - loss: 0.5332 - accuracy: 0.9036 - val_loss: 0.7681 - val_accuracy: 0.8778\n","Epoch 16/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.5187 - accuracy: 0.9055 - val_loss: 0.7609 - val_accuracy: 0.8790\n","Epoch 17/50\n","750/750 [==============================] - 38s 51ms/step - loss: 0.5051 - accuracy: 0.9069 - val_loss: 0.7557 - val_accuracy: 0.8798\n","Epoch 18/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.4923 - accuracy: 0.9087 - val_loss: 0.7514 - val_accuracy: 0.8810\n","Epoch 19/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.4802 - accuracy: 0.9105 - val_loss: 0.7443 - val_accuracy: 0.8822\n","Epoch 20/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.4692 - accuracy: 0.9118 - val_loss: 0.7404 - val_accuracy: 0.8828\n","Epoch 21/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.4587 - accuracy: 0.9132 - val_loss: 0.7366 - val_accuracy: 0.8840\n","Epoch 22/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.4487 - accuracy: 0.9146 - val_loss: 0.7353 - val_accuracy: 0.8848\n","Epoch 23/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.4396 - accuracy: 0.9160 - val_loss: 0.7326 - val_accuracy: 0.8855\n","Epoch 24/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.4315 - accuracy: 0.9167 - val_loss: 0.7301 - val_accuracy: 0.8864\n","Epoch 25/50\n","750/750 [==============================] - 34s 45ms/step - loss: 0.4241 - accuracy: 0.9177 - val_loss: 0.7297 - val_accuracy: 0.8862\n","Epoch 26/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.4171 - accuracy: 0.9183 - val_loss: 0.7279 - val_accuracy: 0.8871\n","Epoch 27/50\n","750/750 [==============================] - 39s 51ms/step - loss: 0.4108 - accuracy: 0.9193 - val_loss: 0.7292 - val_accuracy: 0.8873\n","Epoch 28/50\n","750/750 [==============================] - 39s 51ms/step - loss: 0.4051 - accuracy: 0.9200 - val_loss: 0.7287 - val_accuracy: 0.8875\n","Epoch 29/50\n","750/750 [==============================] - 34s 46ms/step - loss: 0.3991 - accuracy: 0.9206 - val_loss: 0.7282 - val_accuracy: 0.8883\n","Epoch 30/50\n","750/750 [==============================] - 39s 52ms/step - loss: 0.3933 - accuracy: 0.9213 - val_loss: 0.7303 - val_accuracy: 0.8884\n","Epoch 31/50\n","749/750 [============================>.] - ETA: 0s - loss: 0.3883 - accuracy: 0.9221Restoring model weights from the end of the best epoch: 26.\n","750/750 [==============================] - 34s 46ms/step - loss: 0.3884 - accuracy: 0.9221 - val_loss: 0.7325 - val_accuracy: 0.8883\n","Epoch 31: early stopping\n"]}],"source":["##훈련\n","hist = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_output_train, validation_split=0.2,\n","        epochs=50, verbose=1, callbacks=[es])"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"6RQAqnrHfo5H","executionInfo":{"status":"ok","timestamp":1680447283961,"user_tz":-540,"elapsed":563,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":["#인코더 인풋레이어를 입력으로 받아서 마지막시점 은닉상태, 셀상태를 출력으로 하는 모델임 \n","encode_model = keras.models.Model(encoder_layer,encoder_last_states)\n","#이전 시점의 상태를 보관해야됨\n","before_hidden_state = keras.layers.Input(shape= (hidden_dim,))\n","before_cell_state = keras.layers.Input(shape= (hidden_dim,))\n","decoder_state_input = [before_hidden_state, before_cell_state]\n","\n","#train할 때 사용했던 거 그대로 씀 \n","test_embedding_layer = keras.layers.Embedding(fr_dic, hidden_dim)(decoder_layer)\n","#디코더 LSTM출력값, 히든상태, 셀상태\n","decoder_output2, hidden_state2, cell_state2 = lstm_layer(test_embedding_layer, initial_state=decoder_state_input)\n","#상태 저장해주고고\n","decoder_state2 = [hidden_state2, cell_state2]\n","#모든 시점에 대해서 단어 예측하는거임\n","dense_layer2 = decoder_dense(decoder_output2)\n","\n","#모델 시작과 끝 지정\n","#디코더 입력 시퀀스 + 이전 시점의 상태값, 각 시점예측단어 + 마지막 은닉상태 \n","decoder_model = keras.models.Model([decoder_layer] + decoder_state_input, [decoder_output2] + decoder_state2)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"rARbvB3nmKda","executionInfo":{"status":"ok","timestamp":1680447283961,"user_tz":-540,"elapsed":2,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":["#입력 시퀀스를 디코딩하는 함수임ㅇㅇㅇㅇ\n","def decode_sent(input_sent):\n","    #인코딩 모델에 넣음 \n","    states = encode_model.predict(input_sent)\n","    #디코딩 하기전에 <sos> \n","    target_seq = np.zeros((1,1))\n","    target_seq[0,0] = fr_to_index['<sos>']\n","\n","    flag = False\n","    decode_string = ''\n","\n","    while not flag:\n","        #target_seq와 이전 시점의 상태를 입력으로 넣어서 예측값 output_token을 뽑아냄\n","        output_tokens , h, c = decoder_model.predict([target_seq] + states)\n","        #가장 확률이 높은 단어를 sampled_token_index로 지정 , -1은 현재 타임스탭이고, :은 전체에 대한 확률분포\n","        sampled_token_index = np.argmax(output_tokens[0,-1, :])\n","        #index를 문자로 변환\n","        sampled_char = index_to_fr[sampled_token_index]\n","\n","        decode_string = decode_string + ' ' + sampled_char\n","        if (sampled_char == '<eos>' or len(decode_string) > 50):\n","            flag = True\n","        #다음 단어를 예측하기 위해 target_seq 초기화화\n","        target_seq = np.zeros((1,1))\n","        #다음 예측할 단어의 입력으로 지정 \n","        target_seq[0, 0] = sampled_token_index\n","        #상태 업데이트\n","        states = [h, c]\n","\n","    #최종 문장 리턴 \n","    return decode_string\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"5a3Lw2OxwA_r","executionInfo":{"status":"ok","timestamp":1680447283962,"user_tz":-540,"elapsed":3,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":["def beam_decode_sent(input_sent, k=3):\n","    sentence = [[list(), 1.0]] # 빈 리스트와 점수1.0으로 초기화 \n","\n","    for i in input_sent:\n","        all_candidates = list()\n","\n","        for j in range(len(sentence)):\n","            seq, score = sentence[i]\n","            for k in range(len(i)):\n","                candidate = [seq + [k], score * -log(row[k])]\n","                all_candidates.append(candidate)\n","\n","        ordered = sorted(all_candidates, key=lambda x: x[1])\n","        sentence = ordered[:k]\n","    return sentence"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"7--nOfEDsX3v","executionInfo":{"status":"ok","timestamp":1680447474764,"user_tz":-540,"elapsed":799,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":["#입력 시퀀스에 대한 문장을 반환하는 함수 \n","def seq_to_en(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0):\n","        #정수-> 영어 리턴 \n","        sentence = sentence + index_to_en[encoded_word] + ' '\n","  return sentence\n","\n","# 정수 시퀀스를 텍스트 시퀀스로 변환( 번역)\n","def seq_to_fr(input_seq):\n","  sentence = ''\n","  for encoded_word in input_seq:\n","    if(encoded_word != 0 and encoded_word != fr_to_index['<sos>'] and encoded_word != fr_to_index['<eos>']):\n","      sentence = sentence + index_to_fr[encoded_word] + ' '\n","  return sentence"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"4edF1VRZwwIw","executionInfo":{"status":"ok","timestamp":1680447283962,"user_tz":-540,"elapsed":3,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"TajWDiprtK8E","colab":{"base_uri":"https://localhost:8080/","height":726},"outputId":"262b814a-ec9c-43cd-a3ac-0ec47d859aed","executionInfo":{"status":"error","timestamp":1680447479207,"user_tz":-540,"elapsed":2109,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","입력문장 : fire ! \n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-2c1a275799b1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdecode_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"입력문장 :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_to_en\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"정답문장 :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_to_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"번역문장 :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-1d227d22a7b2>\u001b[0m in \u001b[0;36mseq_to_fr\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mencoded_word\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_word\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoded_word\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mindex_to_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoded_word\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mindex_to_fr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfr_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded_word\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '<sos>'"]}],"source":["seq_index = 5\n","input_seq = encoder_input_train[seq_index: seq_index + 1]\n","decode_string = decode_sent(input_seq)\n","print(\"입력문장 :\",seq_to_en(encoder_input_train[seq_index]))\n","print(\"정답문장 :\",seq_to_fr(decoder_input_train[seq_index]))\n","print(\"번역문장 :\",decode_string[1:-5])"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"uXrqsRXktgnZ","executionInfo":{"status":"ok","timestamp":1680447286204,"user_tz":-540,"elapsed":2,"user":{"displayName":"hyun kim","userId":"01411993080668172019"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWz/gLlinYIkbWKuej7+f/"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}